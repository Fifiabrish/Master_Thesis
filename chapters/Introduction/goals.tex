\section{بیان مسئله و اهداف پژوهش}
\label{sec:intro:problem-statement}

محرمانگی تفاضلی موضعی (\lr{LDP}) به عنوان یک حوزه‌ی میان‌رشته‌ای، محل تلاقی «علوم کامپیوتر» (با تمرکز بر طراحی الگوریتم و امنیت) و «آمار ریاضی» (با تمرکز بر نظریه تخمین و مینی‌مکس) است. این ماهیت دوگانه، اگرچه باعث غنای ادبیات موضوع شده، اما منجر به پراکندگی قابل‌توجهی در روش‌ها و ابزارهای تحلیلی گشته است.

همان‌طور که در مرور ادبیات اشاره شد، چارچوب مینی‌مکس که توسط دوچی و همکاران \cite{Duchi2013} پایه‌گذاری شده، نشان می‌دهد که اعمال محدودیت محرمانگی منجر به کاهش نرخ هم‌گرایی در تخمین‌های آماری می‌شود. با این حال، اثبات این نتایج در مقالات مختلف با ابزارهای متفاوتی صورت گرفته است. برای مثال:
\begin{itemize}
    \item در برخی مسائل تخمین چگالی، پژوهشگران عمدتاً از \textbf{واگرایی کولبک-لایبلر (\lr{KL})} و نامساوی فانو استفاده کرده‌اند.
    \item در مسائل آزمون فرض ساده، اغلب از \textbf{فاصله‌ی تغییرات کل (\lr{TV})} و لم لوکام بهره گرفته شده است.
    \item در تحلیل‌های اخیرتر، \textbf{فاصله‌ی کای-دو ($\chi^2$)} به دلیل رفتار هموارتر در همسایگی صفر و ارتباط مستقیم با واریانس، مورد توجه قرار گرفته است.
\end{itemize}

در این پایان‌نامه تلاش شده است تا با گردآوری و بررسی جامع مطالعات پیشین، تحلیلی تطبیقی میان رویکردهای مختلف صورت گیرد و نتایج آن‌ها در چارچوبی منسجم و یک‌پارچه ارائه شود.

\subsection{رویکرد تحلیل: $f$-واگرایی‌ها به عنوان زبان مشترک}
\label{sec:intro:f-div-approach}

برای غلبه بر چالش پراکندگی و ایجاد یکپارچگی نظری، این پایان‌نامه پیشنهاد می‌کند که تمام تحلیل‌ها بر مبنای خانواده‌ی عمومی \textbf{$f$-واگرایی‌ها}\LTRfootnote{$f$-divergences} بازنویسی و تفسیر شوند.
$f$-واگرایی‌ها (معرفی شده توسط سیزار\LTRfootnote{Csiszár})، کلاسی جامع از معیارهای فاصله بین دو توزیع احتمال $P$ و $Q$ هستند:
\begin{equation}
D_f(P \| Q) = \Eset_Q \left[ f\left( \frac{dP}{dQ} \right) \right]
\end{equation}
که در آن $f$ یک تابع محدب با ویژگی $f(1)=0$ است.

انتخاب این رویکرد به ما اجازه می‌دهد تا «محرمانگی» را نه صرفاً به عنوان یک ویژگی الگوریتمی، بلکه به عنوان یک \textbf{محدودیت هندسی} تفسیر کنیم. در این دیدگاه، هر مکانیزم \lr{LDP} مانند یک «کانال انقباضی»\LTRfootnote{Contraction Channel} عمل می‌کند که فاصله‌ی بین توزیع‌های ورودی را فشرده می‌سازد. هدف ما در این پژوهش، بررسی این است که چگونه ادبیات پیشرو، مفهوم «ضریب انقباض»\LTRfootnote{Contraction Coefficient} را برای $f$-واگرایی‌های مختلف محاسبه کرده و از آن برای استخراج کران‌های مینی‌مکس استفاده می‌کنند. این دیدگاه هندسی، پلی میان اثبات‌های پراکنده ایجاد می‌کند و نشان می‌دهد که انتخاب $f$ مناسب، تابعی از هندسه‌ی مسئله است.
\subsection{رویکرد تحلیل: چارچوب انقباض $f$-واگرایی‌ها}
\label{sec:intro:f-div-approach}

برای غلبه بر چالش پراکندگی مفاهیم و ارائه یک تحلیل منسجم، این پایان‌نامه بر مرور و تشریح رویکرد نوینی تمرکز دارد که در سال‌های اخیر توسط **آسوده، علی‌اکبری و کالمون** \cite{Asoodeh2021} و **آسوده و ژانگ** \cite{Asoodeh2024} توسعه یافته است.
این پژوهشگران نشان داده‌اند که قیود محرمانگی تفاضلی موضعی (\lr{LDP}) را می‌توان به‌صورت دقیق و ریاضی معادل با «خواص انقباضی»\LTRfootnote{Contraction Properties} خانواده‌ی $f$-واگرایی‌ها فرمول‌بندی کرد.

به‌طور مشخص، در این رویکرد اثبات می‌شود که شرط \lr{LDP} معادل است با کران‌دار بودن ضریب انقباض برای «واگرایی هاکی-استیک» ($E_\gamma$-divergence). همچنین، تحلیل‌های دقیق‌تر نشان می‌دهند که چگونه می‌توان بهترین کران‌های انقباض را برای واگرایی‌های مهمی نظیر $\chi^2$ و \lr{KL} استخراج کرد.
این دیدگاه هندسی، هر مکانیزم محرمانگی را به مثابه‌ی یک کانال نویزی می‌بیند که فاصله بین توزیع‌های احتمالی ورودی را کاهش می‌دهد. در این پایان‌نامه، ما تلاش می‌کنیم تا با مطالعه‌ی دقیق این مراجع، نشان دهیم چگونه این ضرایب انقباض ($\eta_f$) محاسبه می‌شوند و چگونه می‌توان از آن‌ها برای بازتولید و بهبود کران‌های مینی‌مکس در مسائل تخمین و آزمون فرض استفاده کرد.


\subsection{اهداف و ساختار پژوهش}
\label{sec:intro:objectives}

هدف اصلی این پایان‌نامه، ارائه‌ی یک «مرور تحلیلی و آموزشی» از ادبیات مدرن نظریه مینی‌مکس تحت محدودیت محرمانگی است. ما با محوریت قرار دادن کارهای انجام‌شده توسط محققان نام‌برده، اهداف زیر را دنبال می‌کنیم:

\begin{enumerate}
    \item \textbf{تبیین هم‌ارزی \lr{LDP} و انقباض $E_\gamma$:}
    مرور و بازنویسی اثبات‌های ریاضی که نشان می‌دهند محرمانگی تفاضلی موضعی دقیقاً معادل با انقباض در واگرایی هاکی-استیک است. این بخش بر اساس نتایج \cite{Asoodeh2021} تنظیم شده و پایه‌ای برای تعمیم نتایج به سایر واگرایی‌ها فراهم می‌کند.

    \item \textbf{بررسی ضرایب انقباض برای واگرایی‌های $\chi^2$ و \lr{KL}:}
    مطالعه‌ی کران‌های دقیق\LTRfootnote{Sharp Bounds} برای ضریب انقباض مکانیزم‌های \lr{LDP} تحت واگرایی‌های کای-دو و کولبک-لایبلر. این بخش با تمرکز بر نتایج \cite{Asoodeh2024}، نشان می‌دهد که چگونه می‌توان «نامساوی‌های پردازش داده قوی»\LTRfootnote{Strong Data Processing Inequalities (SDPI)} را برای محیط‌های خصوصی استخراج کرد.

    \item \textbf{یک‌پارچه‌سازی روش‌های کران پایین:}
    تشریح اینکه چگونه ابزارهای انقباضی فوق، در ترکیب با متدهای کلاسیک آماری نظیر «لوکام»، «فانو» و «اسود»، منجر به استخراج حدود بهینه برای خطای تخمین مینی‌مکس می‌شوند. هدف ما نشان دادن این موضوع است که چگونه این چارچوب واحد، نتایج پراکنده در ادبیات را پوشش می‌دهد.
    
    \item \textbf{جمع‌بندی و مقایسه نتایج:}
    انجام مروری ساختاریافته بر کاربردهای این چارچوب در مسائلی نظیر «تخمین میانگین»، «تخمین چگالی» و «آزمون فرض»، و مقایسه نتایج حاصل از رویکرد انقباضی با سایر روش‌های موجود در ادبیات.
\end{enumerate}