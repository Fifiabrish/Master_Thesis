\section{بیان مسئله و اهداف پژوهش}
\label{sec:intro:problem-statement}

محرمانگی تفاضلی موضعی (\lr{LDP}) به عنوان یک حوزه‌ی میان‌رشته‌ای، محل تلاقی «علوم کامپیوتر» (با تمرکز بر طراحی الگوریتم و امنیت) و «آمار ریاضی» (با تمرکز بر نظریه تخمین و مینیماکس) است. این ماهیت دوگانه، اگرچه باعث غنای ادبیات موضوع شده، اما منجر به پراکندگی قابل‌توجهی در روش‌ها و ابزارهای تحلیلی گشته است.

همان‌طور که در مرور ادبیات اشاره شد، چارچوب مینیماکس که توسط دوچی و همکاران \cite{Duchi2013} پایه‌گذاری شده، نشان می‌دهد که اعمال محدودیت محرمانگی منجر به کاهش نرخ هم‌گرایی در تخمین‌های آماری می‌شود. با این حال، اثبات این نتایج در مقالات مختلف با ابزارهای متفاوتی صورت گرفته است که منجر به نوعی «اثر برج بابل» در ادبیات علمی شده است. برای مثال:
\begin{itemize}
    \item در برخی مسائل تخمین چگالی، پژوهشگران عمدتاً از \textbf{واگرایی کولبک-لایبلر (\lr{KL})} و نامساوی فانو استفاده کرده‌اند.
    \item در مسائل آزمون فرض ساده، اغلب از \textbf{فاصله‌ی تغییرات کل (\lr{TV})} و لم لوکام بهره گرفته شده است.
    \item در تحلیل‌های اخیرتر، \textbf{فاصله‌ی کای-دو ($\chi^2$)} به دلیل رفتار هموارتر در همسایگی صفر و ارتباط مستقیم با واریانس، مورد توجه قرار گرفته است.
\end{itemize}

این تنوع در ابزارها، درک هندسی و شهودی از ماهیت «اتلاف اطلاعات» را برای پژوهشگران دشوار می‌سازد. پژوهشگری که قصد ورود به این حوزه را دارد، با مجموعه‌ای از تکنیک‌های اثباتی مجزا روبرو می‌شود که ارتباط درونی آن‌ها شفاف نیست. مسئله‌ی اصلی که این پایان‌نامه بر آن تمرکز دارد، فقدان یک چارچوب یک‌پارچه و منسجم در ادبیات (به‌ویژه منابع فارسی) است که بتواند این ابزارهای به‌ظاهر متفاوت را زیر یک چتر واحد گردآوری و تحلیل کند.

\subsection{رویکرد تحلیل: $f$-واگرایی‌ها به عنوان زبان مشترک}
\label{sec:intro:f-div-approach}

برای غلبه بر چالش پراکندگی و ایجاد یکپارچگی نظری، این پایان‌نامه پیشنهاد می‌کند که تمام تحلیل‌ها بر مبنای خانواده‌ی عمومی \textbf{$f$-واگرایی‌ها}\LTRfootnote{$f$-divergences} بازنویسی و تفسیر شوند.
$f$-واگرایی‌ها (معرفی شده توسط سیسار\LTRfootnote{Csiszár})، کلاسی جامع از معیارهای فاصله بین دو توزیع احتمال $P$ و $Q$ هستند:
\begin{equation}
D_f(P \| Q) = \Eset_Q \left[ f\left( \frac{dP}{dQ} \right) \right]
\end{equation}
که در آن $f$ یک تابع محدب با ویژگی $f(1)=0$ است.

انتخاب این رویکرد به ما اجازه می‌دهد تا «محرمانگی» را نه صرفاً به عنوان یک ویژگی الگوریتمی، بلکه به عنوان یک \textbf{محدودیت هندسی} تفسیر کنیم. در این دیدگاه، هر مکانیزم \lr{LDP} \ مانند یک «کانال انقباضی»\LTRfootnote{Contraction Channel} عمل می‌کند که فاصله‌ی بین توزیع‌های ورودی را فشرده می‌سازد. هدف ما در این پژوهش، بررسی این است که چگونه ادبیات پیشرو، مفهوم «ضریب انقباض»\LTRfootnote{Contraction Coefficient} را برای $f$-واگرایی‌های مختلف محاسبه کرده و از آن برای استخراج کران‌های مینیماکس استفاده می‌کنند. این دیدگاه هندسی، پلی میان اثبات‌های پراکنده ایجاد می‌کند و نشان می‌دهد که انتخاب $f$ مناسب، تابعی از هندسه‌ی مسئله است.

\subsection{اهداف و ساختار پژوهش}
\label{sec:intro:objectives}

هدف نهایی این پایان‌نامه، ارائه‌ی یک «بازخوانی تحلیلی و آموزشی» از نظریه مینیماکس تحت محدودیت محرمانگی است تا شکاف میان مفاهیم علوم کامپیوتر و آمار پر شود. اهداف مشخص این پژوهش عبارتند از:

\begin{enumerate}
    \item \textbf{یک‌پارچه‌سازی مبانی نظری:}
    گردآوری و بازتعریف قضایای بنیادین (مانند نامساوی‌های پردازش داده قوی) با استفاده از نمادگذاری واحد و چارچوب $f$-واگرایی، به‌گونه‌ای که خواننده بتواند ارتباط ریاضی بین معیارهای مختلف \lr{(KL, TV, $\chi^2$)} را به وضوح مشاهده کند.

    \item \textbf{تبیین روش‌های کران پایین:}
    تشریح دقیق و گام‌به‌گام متدهای کلاسیک آماری نظیر «متد دو نقطه‌ای لوکام»\LTRfootnote{Le Cam's Method} و «نامساوی فانو»\LTRfootnote{Fano's Inequality} در بستر محرمانگی. هدف این است که نشان دهیم چگونه می‌توان مسئله‌ی پیچیده‌ی «تخمین» را به مسئله‌ی ساده‌تر «آزمون فرض» تقلیل داد و از هندسه‌ی $f$-واگرایی برای حل آن استفاده کرد.

    \item \textbf{تفسیر هندسی رفتار مکانیزم‌ها:}
    تحلیل «رفتار انقباضی»\LTRfootnote{Contraction Behavior} مکانیزم‌ها با هدف محاسبه‌ی ضرایب انقباض برای $f$-واگرایی‌های مختلف. ما نشان می‌دهیم که چگونه مکانیزم‌های محرمانگی (مانند پاسخ تصادفی) باعث کاهش فاصله بین توزیع‌ها می‌شوند و این کاهش چگونه به طور مستقیم بر خطای تخمین تأثیر می‌گذارد.
    
    \item \textbf{مرور تحلیلی و بازخوانی ادبیات موضوع:}
    انجام مروری جامع و ساختاریافته بر کارهای انجام‌ شده در حوزه‌ی تخمین مینیماکس تحت محدودیت \LDP \ و تحلیل دقیق نتایج موجود با استفاده از ابزار $f$-واگرایی‌ها، به منظور یکپارچه‌سازی اثبات‌های پراکنده و شفاف‌سازی مسیرهای استدلالی برای پژوهشگران این حوزه.
\end{enumerate}