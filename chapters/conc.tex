\chapter{نتیجه‌گیری و پیشنهادها}
\label{ch:conclusion}

\section{جمع‌بندی و دستاوردهای اصلی}
\label{sec:conclusion:summary}

در این پایان‌نامه مروری تحلیلی بر حدود بنیادین دقت آماری در حضور 
محدودیت‌های محرمانگی ارائه شد. پرسش محوری این بود که هزینه اطلاعاتی 
که \lr{LDP} بر داده‌ها تحمیل می‌کند، ذاتی است یا ناشی از ضعف 
الگوریتم‌های موجود.

در فصل دوم، زیربنای ریاضی لازم بنا نهاده شد. تعریف \lr{LDP} نه صرفاً 
به عنوان یک الگوریتم، بلکه به عنوان محدودیتی روی کانال‌های ارتباطی 
معرفی شد و خانواده $f$-واگرایی‌ها به عنوان ابزار اصلی سنجش فاصله میان 
توزیع‌ها مرور گردید. در فصل سوم، مکانیزم‌های استاندارد \lr{LDP} تشریح 
شد و نشان داده شد که هزینه عدم اعتماد به سرور مرکزی، افزایش پیچیدگی 
نمونه از مرتبه $\mathcal{O}(n)$ به $\mathcal{O}(n^2)$ است.

در فصل چهارم، رویکرد پیشگامانه دوچی، جردن و وین‌رایت \cite{duchi2018} 
به تفصیل بررسی شد. در این رویکرد تحلیل‌ها بر مبنای انقباض واگرایی 
\lr{KL} بنا شده و با ابزارهایی نظیر لم اسود و نامساوی فانو، کران‌های 
پایین مینی‌مکس اثبات می‌شوند. در کنار مزایای این رویکرد، محدودیت آن 
نیز تحلیل شد: واگرایی \lr{KL} تقارن و کران‌های ذاتی \LDP\ را به طور 
کامل بازتاب نمی‌دهد و در رژیم‌های محرمانگی متوسط یا بالا، به ضرایب 
نادقیق در کران‌های مینی‌مکس منجر می‌شود.

در فصل پنجم، چارچوب مکمل «انقباض $E_\gam$-واگرایی» بر پایه کارهای 
آسوده و همکاران \cite{asoodeh2021, asoodeh2024} مرور و تحلیل شد. نشان 
داده شد که واگرایی $E_\gam$ با پارامتر $\gam = e^\al$ زبان طبیعی 
\lr{DP} است: شرط \LDP\ دقیقاً معادل با صفر شدن این واگرایی است.

\subsection{دستاوردهای اصلی پژوهش}

مهم‌ترین دستاوردهای این پایان‌نامه به شرح زیر است:

\begin{itemize}

\item \textbf{گذار از تقریب به دقت کامل:}
در رویکرد سنتی (فصل ۴)، استخراج کران‌های پایین مستلزم بسط‌های تیلور 
واگرایی \lr{KL} حول صفر بود که تنها برای $\al$های کوچک معتبر است. 
رویکرد فصل ۵ نشان داد که با استفاده از $E_\gam$ می‌توان مستقیماً و 
بدون تقریب، کران‌هایی استخراج کرد که برای تمام مقادیر 
$\al \in (0, \infty)$ معتبرند.

\item \textbf{اصلاح ضرایب انقباض:}
ضریب انقباض واقعی برای مکانیزم‌های \LDP\ از مرتبه 
$\left(e^\al - 1\right)^2$ است، در حالی که تحلیل‌های مبتنی بر \lr{KL} 
ضریب اضافه $\left(e^\al + 1\right)$ را نیز حمل می‌کردند. این اصلاح 
به ویژه در رژیم‌های محرمانگی متوسط تفاوتی معنادار در تخمین حجم داده 
مورد نیاز ایجاد می‌کند.

\item \textbf{دیدگاه هندسی:}
مسئله طراحی مکانیزم‌های بهینه \LDP\ را می‌توان به عنوان یافتن 
توزیع‌هایی تفسیر کرد که $E_{e^\al}$-واگرایی آن‌ها صفر باشد. این 
دیدگاه درک عمیق‌تری نسبت به تعریف جبری «نسبت احتمالات» فراهم می‌کند 
و راه را برای طراحی مکانیزم‌های جدید هموار می‌سازد.

\end{itemize}

در مجموع، این پایان‌نامه نشان داد که برای تحلیل دقیق سیستم‌های 
خصوصی، باید ابزار واگرایی را با ماهیت ذاتی محدودیت محرمانگی هم‌راستا 
کرد و هزینه اطلاعاتی \lr{LDP} یک مانع هندسی اجتناب‌ناپذیر است.


\section{پیشنهادهایی برای تحقیقات آتی}
\label{sec:future-works}

پژوهش حاضر گامی در جهت یک‌پارچه‌سازی نظریه محرمانگی تفاضلی موضعی 
و بررسی کران‌های مینی‌مکس برداشت. در ادامه مسیرهای پژوهشی‌ای که 
می‌توانند امتداد طبیعی این پایان‌نامه باشند معرفی می‌شوند.

\subsection{تحلیل انقباض در مدل شافل}
مدل شافل\LTRfootnote{Shuffle Model} به عنوان حد واسطی میان مدل‌های 
\lr{LDP} و \lr{CDP} ظهور کرده و ادبیات موجود نشان می‌دهد که عمل شافل 
کردن باعث تقویت محرمانگی\LTRfootnote{Privacy Amplification} می‌شود. 
مسئله‌ای که همچنان باز مانده این است که آیا می‌توان با استفاده از 
چارچوب $E_\gam$-واگرایی، کران‌های دقیق‌تری برای این پدیده نسبت به 
تحلیل‌های مبتنی بر \lr{KL} استخراج کرد یا خیر.

پرسش مرتبط دیگری که پیش می‌آید این است که وقتی پارامتر محرمانگی 
$\eps_i$ برای هر کاربر متفاوت باشد، کران‌های انقباض چگونه تغییر 
می‌کنند و آیا می‌توان کران‌های مینی‌مکس را بر حسب توزیع پیشین روی 
$\eps_i$ بیان کرد.

\subsection{ارتباط با محرمانگی تفاضلی رنی}
محرمانگی تفاضلی رنی\LTRfootnote{Rényi Differential Privacy (RDP)} که 
امروزه استاندارد طلایی تحلیل ترکیب مکانیزم‌ها محسوب می‌شود، بر مبنای 
خانواده واگرایی‌های رنی بنا شده است. بررسی رابطه صریح میان ضرایب 
انقباض به‌دست‌آمده در این پژوهش و انقباض واگرایی‌های رنی، می‌تواند 
پلی میان این دو چارچوب ایجاد کند و بهره‌گیری از ابزارهای قدرتمند 
\lr{RDP} را در تحلیل‌های موضعی ممکن سازد.

\subsection{تخمین‌گرهای تطبیقی}
تمام تحلیل‌های این پایان‌نامه بر فرض ثابت بودن بودجه محرمانگی $\al$ 
استوار بودند. طراحی مکانیزم‌هایی که بودجه خود را به صورت 
تطبیقی\LTRfootnote{Adaptive Mechanisms} و بر اساس سختی داده تنظیم 
کنند مسیر پژوهشی ارزشمندی است. چالش اصلی، اثبات این نکته است که 
فرآیند تنظیم پارامتر خود باعث نقض شرط \LDP\ نشود.

\subsection{تعمیم به داده‌های وابسته}
تمامی کران‌های مینی‌مکس این پایان‌نامه بر فرض استقلال داده‌ها 
(\lr{i.i.d.}) استوار بودند. تعمیم لم 
اسود\LTRfootnote{Assouad's Lemma} و نامساوی‌های انقباض به فرآیندهای 
تصادفی وابسته مانند زنجیره‌های مارکوف نیازمند پژوهش‌های بیشتری است؛ 
زیرا در حضور وابستگی خاصیت تانسوری واگرایی‌ها برقرار نیست و باید 
ابزارهای جدیدی برای سنجش نرخ انباشت اطلاعات توسعه یابد.