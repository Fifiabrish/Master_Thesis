\chapter{نتیجه‌گیری و پیشنهادها}
\label{ch:conclusion}

\section{جمع‌بندی و دستاوردهای اصلی}
\label{sec:conclusion:summary}

در این پایان‌نامه، ما مسیر پرفراز و نشیبی را برای درک حدود نهایی دقت آماری در حضور محدودیت‌های محرمانگی طی کردیم. هدف اصلی ما، پاسخ به این پرسش بود که هزینه اطلاعاتی واقعی که محرمانگی تفاضلی موضعی یا به اختصار \lr{LDP} بر داده‌ها تحمیل می‌کند، چیست و چگونه می‌توان آن را به دقیق‌ترین شکل ممکن مدل‌سازی کرد.

در فصول دوم و سوم، زیربنای ریاضی لازم را بنا نهادیم و تعریف \lr{LDP} را نه صرفاً به عنوان یک الگوریتم، بلکه به عنوان یک محدودیت روی کانال‌های ارتباطی معرفی کردیم و ابزارهای سنجش فاصله از جمله خانواده $f$-واگرایی‌ها را مرور نمودیم. سپس در فصل چهارم، رویکرد کلاسیک و پیشگامانه دوچی و همکاران \cite{duchi2018} را بررسی کردیم. در این رویکرد، تحلیل‌ها بر مبنای انقباض واگرایی \lr{KL} بنا شده‌اند. اگرچه این روش برای رژیم‌های محرمانگی بالا (محدوده‌ای که در آن $\al \to 0$) نتایج قابل قبولی ارائه می‌دهد، اما نشان دادیم که استفاده از واگرایی \lr{KL} برای تحلیل \LDP\ یک انتخاب ناگزیر بوده و نه یک انتخاب طبیعی؛ زیرا این واگرایی تقارن و کران‌های ذاتی \LDP\ را به طور کامل بازتاب نمی‌دهد و منجر به ظهور ضرایب نادقیق در کران‌های مینی‌مکس می‌شود.

% -------------------------------------------------------------------------
% TODO: پس از تکمیل فصل ۵، این بخش‌ها از حالت کامنت خارج و در متن گنجانده شوند:

در فصل پنجم (که هسته اصلی نوآوری این پژوهش بود)، ما چارچوب نوین «انقباض $E_\gam$-واگرایی» را معرفی کردیم. ما نشان دادیم که واگرایی $E_\gam$ (با پارامتر $\gam = e^\al$) زبان مادری و طبیعی \lr{DP} است. اثبات کردیم که \LDP\ معادل با صفر شدن کامل این واگرایی است و این دیدگاه هندسی، ما را قادر ساخت تا کران‌های انقباض را برای سایر معیارها (مانند $\chi^2$) اصلاح و دقیق‌سازی کنیم.

\subsection{دستاوردهای اصلی پژوهش}
مهم‌ترین دستاورد این پایان‌نامه، «یک‌پارچه‌سازی تحلیل \lr{LDP}» از طریق هندسه $E_\gam$ است. نتایج کلیدی ما عبارتند از:

گذار از تقریب به دقت کامل: در روش‌های سنتی (فصل ۴)، برای استخراج کران‌های پایین، ناچار به استفاده از بسط‌های تیلور پیچیده حول صفر برای واگرایی \lr{KL} بودیم. این بسط‌ها تنها برای $\al$های کوچک معتبر بودند. در مقابل، رویکرد فصل ۵ نشان داد که با استفاده از $E_\gam$، می‌توانیم بدون نیاز به بسط تیلور و به صورت مستقیم، کران‌هایی را استخراج کنیم که برای تمام مقادیر $\al \in (0, \infty)$ معتبر و دقیق هستند.

اصلاح ضرایب انقباض: ما نشان دادیم که ضریب انقباض واقعی برای مکانیزم‌های \LDP\ از مرتبه $\left(e^\al - 1\right)^2$ است، در حالی که تحلیل‌های قبلی دارای ضریب اضافه $\left(e^\al + 1\right)$ بودند. این اصلاح، به ویژه در کاربردهایی که بودجه محرمانگی $\al$ مقداری متوسط یا بزرگ دارد (مانند یادگیری ماشین فدرال)، تفاوتی معنادار در تخمین حجم داده مورد نیاز ایجاد می‌کند.

دیدگاه هندسی به جای جبری: این پژوهش نشان داد که مسئله طراحی مکانیزم‌های بهینه \LDP، در واقع مسئله یافتن توزیع‌هایی است که $E_{e^\al}$-واگرایی آن‌ها صفر باشد. این دیدگاه هندسی (قرار گرفتن در همسایگی مشخصی نسبت به متریک $E_\gam$)، درک عمیق‌تری نسبت به تعریف جبری «نسبت احتمالات» فراهم می‌کند و راه را برای طراحی مکانیزم‌های جدید هموار می‌سازد.

به طور خلاصه، این پایان‌نامه نشان داد که برای تحلیل دقیق سیستم‌های خصوصی، باید ابزار تحلیل (متریک واگرایی) را با ماهیت محدودیت (شرط محرمانگی) هم‌راستا کرد. انتخاب $E_\gam$ به عنوان این ابزار، شفافیت و دقت تحلیل‌های آماری در حوزه محرمانگی را به سطح جدیدی ارتقا داده است.
% -------------------------------------------------------------------------


\section{پیشنهادهایی برای تحقیقات آتی}
\label{sec:future-works}

پژوهش حاضر گامی بنیادین در جهت یک‌پارچه‌سازی نظریه محرمانگی تفاضلی موضعی و بررسی دقیق کران‌های مینی‌مکس برداشت. با این حال، همچنان چالش‌های نظری و عملی بسیاری در این حوزه باقی مانده است. در ادامه، مسیرهای پژوهشی اصلی را که می‌توانند به عنوان امتداد طبیعی این پایان‌نامه مورد توجه قرار گیرند، معرفی می‌کنیم.

\subsection{تحلیل انقباض در مدل شافل}
در سال‌های اخیر، مدل شافل\LTRfootnote{Shuffle Model} به عنوان یک حد واسط میان مدل‌های \lr{LDP} و \lr{CDP} ظهور کرده است. ادبیات موجود نشان می‌دهد که عمل شافل کردن باعث تقویت محرمانگی\LTRfootnote{Privacy Amplification} می‌شود. یک مسئله باز جذاب، بررسی این پدیده از دیدگاه دقیق‌تر واگرایی‌ها و بررسی میزان انقباض در این کانال‌ها است. باید بررسی شود که آیا می‌توان نشان داد عملگر شافل، ضریب انقباض را با نرخی بهتر از تحلیل‌های موجود بهبود می‌بخشد یا خیر، و اینکه استفاده از چارچوب‌های هندسی جدید چه تاثیری در ارائه کران‌های دقیق‌تر نسبت به واگرایی تقریبی \lr{KL} خواهد داشت.
\\
یکی از محدودیت‌های مدل‌های فعلی شافل، فرض همگن بودن پارامتر محرمانگی برای همه کاربران است. پرسش جالبی که پیش می‌آید این است که وقتی $\eps_i$
 برای هر کاربر متفاوت باشد، کران‌های انقباض چگونه تغییر می‌کنند؟ آیا می‌توان کران‌های مینی‌مکس را بر حسب توزیع پیشین روی $\eps_i$ بیان کرد؟

\subsection{ارتباط با محرمانگی تفاضلی رنی}
بررسی ارتباط نتایج به دست آمده با محرمانگی تفاضلی رنی\LTRfootnote{Rényi Differential Privacy} یا به اختصار \lr{RDP} که بر مبنای واگرایی‌های رنی بنا شده است، می‌تواند بسیار راهگشا باشد. این چارچوب امروزه استاندارد طلایی برای تحلیل ترکیب مکانیزم‌ها محسوب می‌شود. استخراج فرمول‌های تبدیل و بررسی رابطه صریح میان انقباض واگرایی‌های استفاده شده در این پژوهش و انقباض واگرایی‌های رنی، به ما اجازه می‌دهد تا از ابزارهای قدرتمند \lr{RDP} در تحلیل‌های دقیق‌تر آماری بهره‌مند شویم.

\subsection{تخمین‌گرهای تطبیقی}
در تحلیل‌های مینی‌مکس این پایان‌نامه، فرض بر این بود که بودجه محرمانگی $\al$ ثابت است و مکانیزم $\mech$ به صورت مستقل از داده‌ها عمل می‌کند. یک مسیر تحقیقاتی ارزشمند، طراحی مکانیزم‌هایی است که به صورت تطبیقی\LTRfootnote{Adaptive Estimators} عمل می‌کنند. بدین معنا که مکانیزم ابتدا یک تخمین نویزدار از سختی داده (مانند واریانس محلی) به دست آورد و سپس پارامتر $\al$ را متناسب با آن تنظیم کند. چالش اصلی در این مسیر، اثبات این نکته است که فرآیند تنظیم پارامتر، خود باعث نقض شرط \LDP\ نشود.

\subsection{تعمیم به داده‌های وابسته}
تعمیم نتایج به داده‌های وابسته نیز از دیگر چالش‌های مهم پیش رو است. تمامی کران‌های مینی‌مکس اثبات شده در فصول قبل، بر فرض مستقل و هم‌توزیع بودن\LTRfootnote{i.i.d.} داده‌ها استوار بودند. چگونگی تعمیم لم اسود\LTRfootnote{Assouad's Lemma} و نامساوی‌های انقباض برای فرآیندهای تصادفی وابسته مانند زنجیره‌های مارکوف، نیازمند پژوهش‌های گسترده‌ای است؛ زیرا در حضور وابستگی، خاصیت تانسوری واگرایی‌ها به سادگی برقرار نیست و توسعه ابزارهای جدیدی برای سنجش نرخ انباشت اطلاعات ضرورت می‌یابد.