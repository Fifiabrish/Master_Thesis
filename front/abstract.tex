% -------------------------------------------------------
%  Abstract
% -------------------------------------------------------

\begin{center}
    \textbf{چکیده}
\end{center}

چارچوب «محرمانگی تفاضلی» به عنوان استاندارد طلایی حفاظت از داده‌ها، با ارائه یک ضمانت ریاضی قوی تضمین می‌کند که خروجی الگوریتم‌ها حساسیت معناداری به حضور یا عدم حضور داده‌های یک فرد خاص نداشته باشند. با این وجود، مدل استاندارد و متمرکز این چارچوب نیازمند تجمیع داده‌های خام توسط یک نهاد واسط است. چارچوب «محرمانگی تفاضلی موضعی» به منظور رفع این وابستگی توسعه یافته است؛ در این مدل داده‌ها پیش از تجمیع و در سمت کاربر نویزدار می‌شوند. با این وجود، حل مسئله‌ی اعتماد منجر به چالش بنیادین دیگری می‌شود: افت شدید سودمندی آماری، به گونه‌ای که پیچیدگی تعداد نمونه از مرتبه‌ی $\mathcal{O}(n)$ در مدل متمرکز به تقریب $\mathcal{O}(n^2)$ در مدل موضعی افزایش می‌یابد.

پرسش اساسی این است که آیا این افت چشم‌گیر دقت یک محدودیت ذاتی است یا ناشی از ضعف الگوریتم‌های فعلی. این پایان‌نامه با هدف پاسخ به این پرسش، مروری تحلیلی بر ادبیات پیشرو این حوزه ارائه می‌دهد. در این راستا، دو رویکرد مکمل مطالعه و تلفیق شده‌اند: نخست، چارچوب نظریه مینی‌مکس آماری بر پایه کارهای دوچی، جردن و وین‌رایت، که با ابزارهایی نظیر لم اسود و نامساوی فانو کران‌های پایین خطا را اثبات می‌کند؛ دوم، چارچوب هندسه اطلاعات بر پایه کارهای آسوده و همکاران، که مکانیزم‌های موضعی را به مثابه «کانال‌های انقباض اطلاعات» تفسیر می‌کند.

در این رساله نشان داده می‌شود که شرط محرمانگی تفاضلی موضعی معادل است با انقباض $f$-واگرایی‌ها، و از این هم‌ارزی برای استخراج ضرایب انقباض دقیق برای واگرایی‌های کای-دو، کولبک-لایبلر و هاکی-استیک استفاده می‌شود. ترکیب این ضرایب با ابزارهای کلاسیک نظریه تصمیم آماری، کران‌های پایین مینی‌مکس را به شکلی منسجم و یک‌پارچه اثبات می‌کند و به صراحت نشان می‌دهد که افت سرعت همگرایی به $\mathcal{O}\!\left(\frac{1}{\sqrt{n}}\right)$ یک مانع اطلاعاتی و هندسیِ اجتناب‌ناپذیر است. این چارچوب، معیاری دقیق برای ارزیابی بهینگی الگوریتم‌های آتی در حوزه‌ی حریم خصوصی فراهم می‌سازد.

\vspace{2em}
\noindent\textbf{کلمات کلیدی:} محرمانگی تفاضلی موضعی، نظریه مینی‌مکس آماری، \f-واگرایی‌ها، نامساوی پردازش داده قوی، موازنه دقت-محرمانگی

\newpage