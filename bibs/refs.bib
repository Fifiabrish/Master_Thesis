@inproceedings{dwork2006differential,
  title={Differential privacy},
  author={Dwork, Cynthia},
  booktitle={International colloquium on automata, languages, and programming},
  pages={1--12},
  year={2006},
  organization={Springer}
}

@article{dwork2014roth,
  title={The algorithmic foundations of differential privacy},
  author={Dwork, Cynthia and Roth, Aaron and others},
  journal={Foundations and trends{\textregistered} in theoretical computer science},
  volume={9},
  number={3--4},
  pages={211--407},
  year={2014},
  publisher={Now Publishers, Inc.}
}
@INPROCEEDINGS{narayanan2008robust,
  author={Narayanan, Arvind and Shmatikov, Vitaly},
  booktitle={2008 IEEE Symposium on Security and Privacy (sp 2008)}, 
  title={Robust De-anonymization of Large Sparse Datasets}, 
  year={2008},
  volume={},
  number={},
  pages={111-125},
  keywords={Robustness;Motion pictures;Data security;Data privacy;Transaction databases;Data mining;Internet;Tail;Probability;DVD;Privacy;Anonymity;Attack},
  doi={10.1109/SP.2008.33}
}


@article{sweeney2002k,
author={Sweeney, Latanya},
title = {k-ANONYMITY: A MODEL FOR PROTECTING PRIVACY},
journal = {International Journal of Uncertainty, Fuzziness and Knowledge-Based Systems},
volume = {10},
number = {05},
pages = {557-570},
year = {2002},
doi = {10.1142/S0218488502001648},
URL = {https://doi.org/10.1142/S0218488502001648},
eprint = {https://doi.org/10.1142/S0218488502001648},
}
@article{barbaro2006face,
author = {Barbaro, Michael and Zeller, Tom},
year = {2006},
month = {01},
pages = {},
title = {A Face is exposed for AOL searcher no. 4417749},
journal = {New York Times}
}

@techreport{house2018equifax,
  title={The Equifax Data Breach},
  author={{U.S. House of Representatives Committee on Oversight and Government Reform}},
  year={2018},
  month={December},
  institution={U.S. House of Representatives},
  type={Majority Staff Report},
  url={https://oversight.house.gov/wp-content/uploads/2018/12/Equifax-Report.pdf}
}

@inproceedings{Erlingsson2014,
author = {Erlingsson, \'{U}lfar and Pihur, Vasyl and Korolova, Aleksandra},
title = {RAPPOR: Randomized Aggregatable Privacy-Preserving Ordinal Response},
year = {2014},
isbn = {9781450329576},
publisher = {Association for Computing Machinery},
address = {New York, NY, USA},
url = {https://doi.org/10.1145/2660267.2660348},
doi = {10.1145/2660267.2660348},
abstract = {Randomized Aggregatable Privacy-Preserving Ordinal Response, or RAPPOR, is a technology for crowdsourcing statistics from end-user client software, anonymously, with strong privacy guarantees. In short, RAPPORs allow the forest of client data to be studied, without permitting the possibility of looking at individual trees. By applying randomized response in a novel manner, RAPPOR provides the mechanisms for such collection as well as for efficient, high-utility analysis of the collected data. In particular, RAPPOR permits statistics to be collected on the population of client-side strings with strong privacy guarantees for each client, and without linkability of their reports. This paper describes and motivates RAPPOR, details its differential-privacy and utility guarantees, discusses its practical deployment and properties in the face of different attack models, and, finally, gives results of its application to both synthetic and real-world data.},
booktitle = {Proceedings of the 2014 ACM SIGSAC Conference on Computer and Communications Security},
pages = {1054–1067},
numpages = {14},
keywords = {cloud computing, crowdsourcing, population statistics, privacy protection, statistical inference},
location = {Scottsdale, Arizona, USA},
series = {CCS '14}
}
@article{warner1965randomized,
  title={Randomized response: A survey technique for eliminating evasive answer bias},
  author={Warner, Stanley L},
  journal={Journal of the American statistical association},
  volume={60},
  number={309},
  pages={63--69},
  year={1965},
  publisher={Taylor \& Francis}
}
@INPROCEEDINGS{whatcanwelearnprivatly,
  author={Kasiviswanathan, Shiva Prasad and Lee, Homin K. and Nissim, Kobbi and Raskhodnikova, Sofya and Smith, Adam},
  booktitle={2008 49th Annual IEEE Symposium on Foundations of Computer Science}, 
  title={What Can We Learn Privately?}, 
  year={2008},
  volume={},
  number={},
  pages={531-540},
  keywords={Computer science;Data privacy;Databases;Blood pressure;History;Cardiac arrest;Polynomials;Aggregates;Context modeling;Information analysis;Database Privacy;Learning Theory;PAC Learning},
  doi={10.1109/FOCS.2008.27}}

@article{csiszar1963information,
  title={Eine informationstheoretische Ungleichung und ihre Anwendung auf den Beweis der Ergodizit{\"a}t von Markoffschen Ketten},
  author={Csisz{\'a}r, Imre},
  journal={A Magyar Tudom{\'a}nyos Akad{\'e}mia Matematikai Kutat{\'o} Int{\'e}zet{\'e}nek K{\"o}zlem{\'e}nyei},
  volume={8},
  number={1-2},
  pages={85--108},
  year={1963},
  publisher={Akad{\'e}miai Kiad{\'o}}
}

@article{Ali1966Silvey,
  author = {Ali, S. M. and Silvey, S. D.},
  title = {A General Class of Coefficients of Divergence of One Distribution from Another},
  journal = {Journal of the Royal Statistical Society: Series B (Methodological)},
  volume = {28},
  number = {1},
  pages = {131-142},
  year = {1966}
}

@inproceedings{Duchi2013,
  author={Duchi, John C. and Jordan, Michael I. and Wainwright, Martin J.},
  booktitle={2013 IEEE 54th Annual Symposium on Foundations of Computer Science}, 
  title={Local Privacy and Statistical Minimax Rates}, 
  year={2013},
  volume={},
  number={},
  pages={429-438},
  keywords={Privacy;Estimation;Data privacy;Zinc;Upper bound;Mutual information;TV;Differential privacy;minimax rates;estimation},
  doi={10.1109/FOCS.2013.53}
}

@inproceedings{Cuff2016,
  author = {Paul Cuff and Lanqing Yu},
  booktitle = {Proceedings of the ACM Conference on Computer and Communications Security},
  pages = {43-54},
  title = {Differential privacy as a mutual information constraint},
  year = {2016}
}

@ARTICLE{Asoodeh2024,
  author={Asoodeh, Shahab and Zhang, Huanyu},
  journal={IEEE Journal on Selected Areas in Information Theory}, 
  title={Contraction of Locally Differentially Private Mechanisms}, 
  year={2024},
  volume={5},
  number={},
  pages={385-395},
  keywords={Privacy;Estimation;Upper bound;Mutual information;Entropy;Differential privacy;Data processing;Data integrity;Risk management;Minimax techniques;Differential privacy;data processing inequality;contraction coefficient;minimax estimation risk;f-divergences},
  doi={10.1109/JSAIT.2024.3397305}}


@article{Barnes2020,
  author = {Leighton Pate Barnes and Wei Ning Chen and Ayfer Özgür},
  journal = {IEEE Journal on Selected Areas in Information Theory},
  pages = {645-659},
  title = {Fisher information under local differential privacy},
  volume = {1},
  year = {2020}
}

@inproceedings{Asoodeh2021,
author = {Asoodeh, Shahab and Aliakbarpour, Maryam and Calmon, Flavio P.},
title = {Local Differential Privacy Is Equivalent to Contraction of an $f$-Divergence},
year = {2021},
publisher = {IEEE Press},
url = {https://doi.org/10.1109/ISIT45174.2021.9517999},
doi = {10.1109/ISIT45174.2021.9517999},
abstract = {We investigate the local differential privacy (LDP) guarantees of a randomized privacy mechanism via its contraction properties. We first show that LDP constraints can be equivalently cast in terms of the contraction coefficient of the $mathsf{E}_{gamma}$-divergence. We then use this equivalent formula to express LDP guarantees of privacy mechanisms in terms of contraction coefficients of arbitrary $f$-divergences. When combined with standard estimation-theoretic tools (such as Le Cam's and Fano's converse methods), this result allows us to study the trade-off between privacy and utility in several testing and minimax and Bayesian estimation problems.},
booktitle = {2021 IEEE International Symposium on Information Theory (ISIT)},
pages = {545–550},
numpages = {6},
location = {Melbourne, Australia}
}



@inproceedings{Asoodeh2020,
  title={Contraction of \$E\_\gamma\$-Divergence and Its Applications to Privacy},
  author={Shahab Asoodeh and Mario D{\'i}az and Fl{\'a}vio du Pin Calmon},
  year={2020},
  url={https://api.semanticscholar.org/CorpusID:256808341}
}

@article{Hsu2021,
  author = {Hsiang Hsu and Natalia Martinez and Martin Bertran and Guillermo Sapiro and Flavio P. Calmon},
  journal = {IEEE BITS the Information Theory Magazine},
  pages = {45-56},
  title = {A Survey on Statistical, Information, and Estimation—Theoretic Views on Privacy},
  volume = {1},
  year = {2021}
}

@article{Kairouz2016,
author = {Kairouz, Peter and Oh, Sewoong and Viswanath, Pramod},
title = {Extremal mechanisms for local differential privacy},
year = {2016},
issue_date = {January 2016},
publisher = {JMLR.org},
volume = {17},
number = {1},
issn = {1532-4435},
abstract = {Local differential privacy has recently surfaced as a strong measure of privacy in contexts where personal information remains private even from data analysts. Working in a setting where both the data providers and data analysts want to maximize the utility of statistical analyses performed on the released data, we study the fundamental trade-off between local differential privacy and utility. This trade-off is formulated as a constrained optimization problem: maximize utility subject to local differential privacy constraints. We introduce a combinatorial family of extremal privatization mechanisms, which we call staircase mechanisms, and show that it contains the optimal privatization mechanisms for a broad class of information theoretic utilities such as mutual information and f-divergences. We further prove that for any utility function and any privacy level, solving the privacy-utility maximization problem is equivalent to solving a finite-dimensional linear program, the outcome of which is the optimal staircase mechanism. However, solving this linear program can be computationally expensive since it has a number of variables that is exponential in the size of the alphabet the data lives in. To account for this, we show that two simple privatization mechanisms, the binary and randomized response mechanisms, are universally optimal in the low and high privacy regimes, and well approximate the intermediate regime.},
journal = {J. Mach. Learn. Res.},
month = jan,
pages = {492–542},
numpages = {51},
keywords = {estimation, f-divergences, hypothesis testing, information theoretic utilities, local differential privacy, mutual information, privacy-preserving machine learning algorithms, statistical inference}
}

@article{nsal2024,
  author = {Ayşe Ünsal and Melek Önen},
  journal = {ACM Computing Surveys},
  title = {Information-Theoretic Approaches to Differential Privacy},
  volume = {56},
  year = {2024}
}

@article{duchi2018,
  title={Minimax optimal procedures for locally private estimation},
  author={Duchi, John C and Jordan, Michael I and Wainwright, Martin J},
  journal={Journal of the American Statistical Association},
  volume={113},
  number={521},
  pages={182--201},
  year={2018},
  publisher={Taylor \& Francis}
}

@article{Wang2020,
  author = {Teng Wang and Xuefeng Zhang and Jingyu Feng and Xinyu Yang},
  journal = {Sensors},
  pages = {1-48},
  title = {A comprehensive survey on local differential privacy toward data statistics and analysis},
  volume = {20},
  year = {2020}
}